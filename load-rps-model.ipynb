from tensorflow.keras.models import load_model
from google.colab import files
from tensorflow.keras.preprocessing import image
import numpy as np

# Define class names (must match training dataset order)
class_names = ['rock', 'paper', 'scissors']

# Load trained model
model = load_model('/content/sample_data/rps_model.h5')

# If you want, you can recompile (not required for prediction)
# model.compile(optimizer='adam',
#               loss='sparse_categorical_crossentropy',
#               metrics=['accuracy'])

# Upload image(s)
uploaded = files.upload()
for fn in uploaded.keys():
    img_path = fn

    # Load with same target size as training
    img = image.load_img(img_path, target_size=(150, 150))
    img_array = image.img_to_array(img)

    # Add batch dimension
    img_array = np.expand_dims(img_array, axis=0)

    # Normalize
    img_array = img_array / 255.0

    # Predict
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions[0])
    confidence = np.max(predictions[0])

    print(f"File: {fn}")
    print(f"Prediction: {class_names[predicted_class]}")
    print(f"Confidence: {confidence:.2f}")
